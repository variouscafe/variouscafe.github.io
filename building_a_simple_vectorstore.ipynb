{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/variouscafe/variouscafe.github.io/blob/master/building_a_simple_vectorstore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9-U7DdjO9CB"
      },
      "source": [
        "# 키 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPxjrFWNL2BL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVAKFkmKO_Xc"
      },
      "source": [
        "# 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcnianpnLvV1",
        "outputId": "c0f95fb7-d7f3-4085-a993-ffe4805f90f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.3\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.33-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai # openai 라이브러리를 설치합니다.\n",
        "!pip install langchain # 랭체인 라이브러리를 설치합니다.\n",
        "!pip install tqdm\n",
        "!pip install chromadb # 벡터스토어\n",
        "!pip install tiktoken # 토큰 계산용\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_OFQTkbMeDP"
      },
      "source": [
        "# RAG를 위한 파일 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1F_2X0_MZw9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\",\n",
        "    filename=\"state_of_the_union.txt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FnesyzMM4aM"
      },
      "source": [
        "# 랭체인기반 벡터스토어 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XgWMroNMbu_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "raw_documents = TextLoader('state_of_the_union.txt').load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W6D0Gv2fkjf"
      },
      "outputs": [],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxhqgEX9NEqj"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv0jAyOtNHDK"
      },
      "outputs": [],
      "source": [
        "documents[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hdHUufeNRWz"
      },
      "outputs": [],
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_CdliUUNVFn"
      },
      "outputs": [],
      "source": [
        "embedding_vector = OpenAIEmbeddings().embed_query(query)\n",
        "docs = db.similarity_search_by_vector(embedding_vector)\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwjUMOH7NYF0"
      },
      "outputs": [],
      "source": [
        "len(embedding_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGPNZvgaNajH"
      },
      "outputs": [],
      "source": [
        "embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eetk8qr2xaAw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujBxb2vyNj7Y"
      },
      "source": [
        "# SimpleTextLoader 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBxqJH70Gsdq"
      },
      "outputs": [],
      "source": [
        "class SimpleTextLoader:\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def load(self):\n",
        "        text = ''\n",
        "        with open(self.file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "        return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6g-3eEN84g"
      },
      "source": [
        "# SimpleCharacterTextSplitter 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1DMW5kbGOcF"
      },
      "outputs": [],
      "source": [
        "class SimpleCharacterTextSplitter:\n",
        "\n",
        "    def __init__(self, chunk_size, chunk_overlap, separator_pattern='\\n\\n'):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.separator_pattern = separator_pattern\n",
        "\n",
        "    def split_documents(self, documents):\n",
        "\n",
        "        splits = documents.split(self.separator_pattern)\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = splits[0]\n",
        "\n",
        "        for split in tqdm(splits[1:], desc=\"splitting...\"):\n",
        "\n",
        "            if len(current_chunk) + len(split) + len(self.separator_pattern) > self.chunk_size:\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = split\n",
        "            else:\n",
        "                current_chunk += self.separator_pattern\n",
        "                current_chunk += split\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJgKupuSN_Qm"
      },
      "source": [
        "# SimpleOpenAIEmbeddings 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBwJ0X4tOZsg"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "class SimpleOpenAIEmbeddings:\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        client = OpenAI()\n",
        "        response = client.embeddings.create(\n",
        "            input=text,\n",
        "            model=\"text-embedding-ada-002\"\n",
        "        )\n",
        "        return response.data[0].embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UWjGahVOCTI"
      },
      "source": [
        "# SimpleVectorStore 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jXSk7yvGiro"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class SimpleVectorStore:\n",
        "    def __init__(self, docs, embedding):\n",
        "        self.embedding = embedding\n",
        "        self.documents = []\n",
        "        self.vectors = []\n",
        "\n",
        "        for doc in tqdm(docs, desc=\"embedding...\"):\n",
        "            self.documents.append(doc)\n",
        "            vector = self.embedding.embed_query(doc)\n",
        "            self.vectors.append(vector)\n",
        "\n",
        "    def similarity_search(self, query, k=4):\n",
        "        query_vector = self.embedding.embed_query(query)\n",
        "\n",
        "        if not self.vectors:\n",
        "            return []\n",
        "\n",
        "        similarities = cosine_similarity([query_vector], self.vectors)[0]\n",
        "        sorted_doc_similarities = sorted(zip(self.documents, similarities), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return sorted_doc_similarities[:k]\n",
        "\n",
        "    def as_retriever(self, k=4):\n",
        "        return SimpleRetriever(self, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3i6rBYmOGXS"
      },
      "source": [
        "# SimpleRetriever 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hL_s18GOJcd"
      },
      "outputs": [],
      "source": [
        "class SimpleRetriever:\n",
        "    def __init__(self, vector_store, k=4):\n",
        "        self.vector_store = vector_store\n",
        "        self.k = k\n",
        "\n",
        "    def get_relevant_documents(self, query):\n",
        "        docs = self.vector_store.similarity_search(query, self.k)\n",
        "        return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb1WQKxvNCt-"
      },
      "outputs": [],
      "source": [
        "raw_documents = SimpleTextLoader('state_of_the_union.txt').load()\n",
        "text_splitter = SimpleCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "db = SimpleVectorStore(documents, SimpleOpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK9aCKigT6ji"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St6ajzvWXwwt"
      },
      "outputs": [],
      "source": [
        "documents[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DqKXzOsZe7v"
      },
      "outputs": [],
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEbh45OPOncP"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW2cIJpsOrk4"
      },
      "outputs": [],
      "source": [
        "print(docs[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIiBUWhJOx6T"
      },
      "source": [
        "# 한글 벡터스토어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF4r_Zr0O5qq"
      },
      "source": [
        "# 헌법 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PDZHS0tGL1_"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/puzzlet/constitution-kr/master/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%20%ED%97%8C%EB%B2%95.txt\",\n",
        "    filename=\"korea_constitution.txt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpW0qZHkjh_8"
      },
      "outputs": [],
      "source": [
        "raw_documents = SimpleTextLoader('korea_constitution.txt').load()\n",
        "text_splitter = SimpleCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCeIlFs_l9z3"
      },
      "outputs": [],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmzl3gKYl89r"
      },
      "outputs": [],
      "source": [
        "db = SimpleVectorStore(documents, SimpleOpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut0L5k29crOe"
      },
      "outputs": [],
      "source": [
        "query = \"대통령 임기는?\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frGJX-7zmd1N"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L37G4oayPkfV"
      },
      "source": [
        "# 벡터스토어 튜닝하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN_28Z2gQqAW"
      },
      "outputs": [],
      "source": [
        "raw_documents = SimpleTextLoader('korea_constitution.txt').load()\n",
        "text_splitter = SimpleCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_1me4SzQwpE"
      },
      "outputs": [],
      "source": [
        "documents[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bibwj9YQvcf"
      },
      "outputs": [],
      "source": [
        "db = SimpleVectorStore(documents, SimpleOpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMfUc6JuQ1ed"
      },
      "outputs": [],
      "source": [
        "query = \"대통령 임기는 몇 년인가?\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9aazNPeQ-nU"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jphpl7QKTAsH"
      },
      "outputs": [],
      "source": [
        "query = \"대통령 임기는?\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsZeIal6THJF"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f72fQjDrQ6MB"
      },
      "source": [
        "# 검색기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rUvpnb3p5DA"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OQQYE-Nr1lm"
      },
      "outputs": [],
      "source": [
        "unique_docs = retriever.get_relevant_documents(query=\"대통령의 임기는 몇 년인가?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxDJ1jU8simP"
      },
      "outputs": [],
      "source": [
        "unique_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9cnbIn3RHIH"
      },
      "source": [
        "# 챗봇 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms0zcp_3trll"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "system_prompt_template = (\"You are a helpful assistant. \"\n",
        "                          \"Based on the following content, \"\n",
        "                          \"kindly and comprehensively respond to user questions. write in Korean.\"\n",
        "                          \"[Content]\"\n",
        "                          \"{content}\"\n",
        "                          \"\")\n",
        "\n",
        "class SimpleRetrievalQA():\n",
        "\n",
        "    def __init__(self, retriever):\n",
        "        self.retriever = retriever\n",
        "\n",
        "    def invoke(self, query):\n",
        "        docs = self.retriever.get_relevant_documents(query)\n",
        "        print(docs)\n",
        "\n",
        "        for i, doc in enumerate(docs):\n",
        "            print(\"[#\" + str(i) + \"]\", doc[1])\n",
        "            print(doc[0])\n",
        "\n",
        "        completion = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt_template.format(content=docs)},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w3C_P2kyAx3"
      },
      "outputs": [],
      "source": [
        "chain = SimpleRetrievalQA(retriever)\n",
        "\n",
        "answer = chain.invoke(\"대통령의 임기는?\")\n",
        "\n",
        "print(\">> \", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TRqfAtwRT3O"
      },
      "outputs": [],
      "source": [
        "chain = SimpleRetrievalQA(retriever)\n",
        "\n",
        "answer = chain.invoke(\"대통령은 중임할 수 있나요?\")\n",
        "\n",
        "print(\">> \", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayCLOWi1yJht"
      },
      "outputs": [],
      "source": [
        "def chat_with_user(user_message):\n",
        "    ai_message = chain.invoke(user_message)\n",
        "    return ai_message\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"USER > \")\n",
        "    if user_message.lower() == \"quit\":\n",
        "        break\n",
        "    ai_message = chat_with_user(user_message)\n",
        "    print(f\" A I > {ai_message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T41j1-pbch3J"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(k=3)\n",
        "chain = SimpleRetrievalQA(retriever)\n",
        "answer = chain.invoke(\"대통령의 임기는?\")\n",
        "\n",
        "print(\">> \", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT2jhROlTfyg"
      },
      "source": [
        "# 로컬 임베딩 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSePE_HOcOh9"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtdPYQMfb5L8"
      },
      "outputs": [],
      "source": [
        "raw_documents = SimpleTextLoader('korea_constitution.txt').load()\n",
        "text_splitter = SimpleCharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-sts\")\n",
        "\n",
        "db = SimpleVectorStore(documents, embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVzRCZF7cdUP"
      },
      "outputs": [],
      "source": [
        "query = \"대통령의 임기는?\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cIVwnhPdr4a"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIRvE7aYkRS2"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(k=5)\n",
        "chain = SimpleRetrievalQA(retriever)\n",
        "answer = chain.invoke(\"대통령의 임기는?\")\n",
        "\n",
        "print(\">> \", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvTr3lKaTvq-"
      },
      "outputs": [],
      "source": [
        "def chat_with_user(user_message):\n",
        "    ai_message = chain.invoke(user_message)\n",
        "    return ai_message\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"USER > \")\n",
        "    if user_message.lower() == \"quit\":\n",
        "        break\n",
        "    ai_message = chat_with_user(user_message)\n",
        "    print(f\" A I > {ai_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f5ss3BNUdfA"
      },
      "source": [
        "# 다른 검색기 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6q60AI-Uft-"
      },
      "outputs": [],
      "source": [
        "!pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9v7K8bJVkiM"
      },
      "outputs": [],
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text(\"2024 small llm?\", max_results=5)]\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaA9vra-Urwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class SimpleWebSearch:\n",
        "    def __init__(self, docs=None, embedding=None):\n",
        "        self.documents = []\n",
        "\n",
        "    def similarity_search(self, query, k=4):\n",
        "        docs = []\n",
        "\n",
        "        with DDGS() as ddgs:\n",
        "            results = [r for r in ddgs.text(query, max_results=k)]\n",
        "\n",
        "        for result in results:\n",
        "            doc = (result['title'] + \":\" + result['body'] + \" - \" + result['href'], 0.0)\n",
        "            docs.append(doc)\n",
        "\n",
        "        return docs\n",
        "\n",
        "    def as_retriever(self, k=4):\n",
        "        return SimpleRetriever(self, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBQI81exXZhm"
      },
      "outputs": [],
      "source": [
        "sws = SimpleWebSearch()\n",
        "web_retriever = sws.as_retriever()\n",
        "chain = SimpleRetrievalQA(web_retriever)\n",
        "answer = chain.invoke(\"What is the latest model created by OpenAI?\")\n",
        "\n",
        "print(\">> \", answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}